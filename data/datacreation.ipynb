{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b848-c4e9-4800-a7ac-5639e90fa0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Mixtures:  11%|█         | 43/387 [00:18<02:41,  2.13it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  31%|███       | 119/387 [00:51<01:47,  2.50it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  31%|███       | 120/387 [00:52<01:46,  2.51it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  31%|███▏      | 121/387 [00:52<01:47,  2.48it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  32%|███▏      | 122/387 [00:53<01:47,  2.48it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  32%|███▏      | 124/387 [00:53<01:47,  2.45it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  39%|███▊      | 149/387 [01:03<01:30,  2.62it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  39%|███▉      | 150/387 [01:04<01:32,  2.57it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  39%|███▉      | 152/387 [01:05<01:36,  2.44it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  45%|████▌     | 176/387 [01:14<01:24,  2.51it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  46%|████▌     | 177/387 [01:15<01:25,  2.47it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  50%|█████     | 194/387 [01:21<01:21,  2.37it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  52%|█████▏    | 202/387 [01:24<01:13,  2.51it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  55%|█████▍    | 211/387 [01:28<01:10,  2.49it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  55%|█████▌    | 213/387 [01:29<01:10,  2.47it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  55%|█████▌    | 214/387 [01:29<01:09,  2.49it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  56%|█████▌    | 215/387 [01:30<01:08,  2.52it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures:  56%|█████▌    | 216/387 [01:30<01:10,  2.44it/s]c:\\Users\\jejep\\anaconda3\\envs\\ProjectEnv\\Lib\\site-packages\\pyloudnorm\\normalize.py:31: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "Creating Mixtures: 100%|██████████| 387/387 [02:37<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset and metadata saved in 'C:\\Users\\jejep\\Desktop\\STAGE\\data\\mixture_audio'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyloudnorm as pyln\n",
    "import random\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "from config import DATASET_PERCUSSION_PATH, DATASET_NOISE_PATH, DATASET_MIX_AUDIO_PATH\n",
    "#%%\n",
    "# Setup\n",
    "random.seed(42)  # Ensure reproducibility\n",
    "\n",
    "# Loudness meter\n",
    "sample_rate = 7812\n",
    "meter = pyln.Meter(sample_rate)\n",
    "\n",
    "# Noise classes\n",
    "noise_class_list = [\n",
    "    'air_conditioner',\n",
    "    'car_horn',\n",
    "    'children_playing',\n",
    "    'dog_bark',\n",
    "    'drilling',\n",
    "    'engine_idling',\n",
    "    'siren',\n",
    "    'jackhammer'\n",
    "]\n",
    "\n",
    "def pad_audio_center(audio_path, sample_rate=7812, target_length=31248):\n",
    "    audio, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        pad_len = (target_length - len(audio)) // 2\n",
    "        audio = numpy.pad(audio, (pad_len, target_length -\n",
    "                       len(audio) - pad_len), 'constant')\n",
    "    \n",
    "    audio = audio[:target_length]\n",
    "    # audio = torch.tensor(audio, dtype=torch.float32)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Helper functions for normalization and mixing\n",
    "def normalize_loudness(audio, target_loudness=-3):\n",
    "    loudness = meter.integrated_loudness(audio)\n",
    "    if loudness == -float('inf'):\n",
    "        audio = pyln.normalize.peak(audio, 0)\n",
    "        loudness = meter.integrated_loudness(audio)\n",
    "\n",
    "    audio = pyln.normalize.loudness(audio, loudness, target_loudness)\n",
    "    \n",
    "    # Ensure audio is within [-1, 1]\n",
    "    max_amplitude = max(abs(audio))\n",
    "    audio = audio / max_amplitude\n",
    "    return audio\n",
    "\n",
    "def create_mixture(percussion_audio, noise_audio, k):\n",
    "    percussion_audio = k * percussion_audio\n",
    "    noise_audio = (1 - k) * noise_audio\n",
    "    mixture_audio = percussion_audio + noise_audio\n",
    "    return mixture_audio\n",
    "\n",
    "# Dataset Creation\n",
    "def create_dataset(metadata_noise, output_dir, num_mixes=7358, target_loudness=-3, max_noise_classes=2, k_values=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    # Create directories if they do not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create a list for storing metadata\n",
    "    metadata = []\n",
    "\n",
    "    # Iterate through the percussion files\n",
    "    percussion_files = sorted(os.listdir(DATASET_PERCUSSION_PATH)) \n",
    "    # keep wav files only\n",
    "    percussion_files = [f for f in percussion_files if f.endswith('.wav')]\n",
    "    \n",
    "    # Progress bar\n",
    "    for perc_idx, perc_file in enumerate(tqdm(percussion_files, desc=\"Creating Mixtures\")):\n",
    "        percussion_path = os.path.join(DATASET_PERCUSSION_PATH, perc_file)\n",
    "        percussion_audio = pad_audio_center(percussion_path)\n",
    "        percussion_audio = normalize_loudness(percussion_audio, target_loudness)\n",
    "\n",
    "        # Randomly select 1 or 2 noise classes for each mix\n",
    "        for _ in range(num_mixes // len(percussion_files)):\n",
    "            num_noise_classes = random.randint(1, max_noise_classes)\n",
    "            noise_classes = random.sample(noise_class_list, k=num_noise_classes)\n",
    "            k = random.choice(k_values)\n",
    "            noise_audio_combined = numpy.zeros_like(percussion_audio)\n",
    "\n",
    "            noise_files = []\n",
    "            noise_classes_str = []\n",
    "\n",
    "            # Load and mix noise files\n",
    "            for noise_class in noise_classes:\n",
    "                noise_row = metadata_noise[metadata_noise['class'] == noise_class].sample(n=1).iloc[0]\n",
    "                noise_file = os.path.join(DATASET_NOISE_PATH, f\"fold{noise_row['fold']}\", noise_row['slice_file_name'])\n",
    "                noise_audio = pad_audio_center(noise_file)\n",
    "                noise_audio = normalize_loudness(noise_audio, target_loudness)\n",
    "\n",
    "                # Add noise to combined noise audio\n",
    "                noise_audio_combined += noise_audio\n",
    "\n",
    "                # Keep track of noise files and classes\n",
    "                noise_files.append(noise_row['slice_file_name'])\n",
    "                noise_classes_str.append(noise_class)\n",
    "\n",
    "            # Create the final mixture\n",
    "            noise_audio_combined = normalize_loudness(noise_audio_combined, target_loudness)\n",
    "            mixture_audio = create_mixture(percussion_audio, noise_audio_combined, k)\n",
    "\n",
    "            # Save mixture audio\n",
    "            mix_file_name = f\"mixture_{perc_idx}_noise_{'_'.join(noise_classes)}_k_{k:.2f}.wav\"\n",
    "            mix_file_path = os.path.join(output_dir, mix_file_name)\n",
    "            sf.write(mix_file_path, mixture_audio, sample_rate)\n",
    "\n",
    "            # Append metadata\n",
    "            metadata.append({\n",
    "                'percussion_file': perc_file,\n",
    "                'mix_file': mix_file_name,\n",
    "                'noise_files': ','.join(noise_files),\n",
    "                'noise_classes': ','.join(noise_classes_str),\n",
    "                'k': k\n",
    "            })\n",
    "\n",
    "    # Save metadata to CSV\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    metadata_df.to_csv(os.path.join(output_dir, \"metadata.csv\"), index=False)\n",
    "    print(f\"Dataset and metadata saved in '{output_dir}'\")\n",
    "\n",
    "# Load noise metadata\n",
    "metadata_noise_path = os.path.join(DATASET_NOISE_PATH, \"UrbanSound8k.csv\")\n",
    "metadata_noise = pd.read_csv(metadata_noise_path)\n",
    "\n",
    "# Change classID 8 to 6\n",
    "metadata_noise['classID'] = metadata_noise['classID'].replace(8, 6)\n",
    "# Sort by class ID and fold and reset index\n",
    "metadata_noise = metadata_noise.sort_values(\n",
    "    by=['classID', 'fold']).reset_index(drop=True)\n",
    "\n",
    "# # Get unique noise classes and their IDs\n",
    "# noise_class = metadata_noise['class'].unique()\n",
    "# noise_classID = metadata_noise['classID'].unique()\n",
    "\n",
    "# # Create a DataFrame for noise classes\n",
    "# noise_data = {\n",
    "#     'class': noise_class,\n",
    "#     'classID': noise_classID,\n",
    "#     'count': [len(metadata_noise[metadata_noise['class'] == c]) for c in noise_class],\n",
    "# }\n",
    "# df = pd.DataFrame(noise_data)\n",
    "\n",
    "# Create dataset with mixtures and save metadata\n",
    "output_dir = DATASET_MIX_AUDIO_PATH\n",
    "create_dataset(metadata_noise, output_dir, num_mixes=7358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Setup\n",
    "random.seed(42)  # Ensure reproducibility\n",
    "\n",
    "# Loudness meter\n",
    "sample_rate = 7812\n",
    "meter = pyln.Meter(sample_rate)\n",
    "\n",
    "# Noise classes\n",
    "noise_class_list = [\n",
    "    'air_conditioner',\n",
    "    'car_horn',\n",
    "    'children_playing',\n",
    "    'dog_bark',\n",
    "    'drilling',\n",
    "    'engine_idling',\n",
    "    'siren',\n",
    "    'jackhammer'\n",
    "]\n",
    "\n",
    "def pad_audio_center(audio_path, sample_rate=7812, target_length=31248):\n",
    "    audio, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        pad_len = (target_length - len(audio)) // 2\n",
    "        audio = numpy.pad(audio, (pad_len, target_length -\n",
    "                       len(audio) - pad_len), 'constant')\n",
    "    \n",
    "    audio = audio[:target_length]\n",
    "    # audio = torch.tensor(audio, dtype=torch.float32)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Helper functions for normalization and mixing\n",
    "def normalize_loudness(audio, target_loudness=-3):\n",
    "    loudness = meter.integrated_loudness(audio)\n",
    "    if loudness == -float('inf'):\n",
    "        audio = pyln.normalize.peak(audio, 0)\n",
    "        loudness = meter.integrated_loudness(audio)\n",
    "\n",
    "    audio = pyln.normalize.loudness(audio, loudness, target_loudness)\n",
    "    \n",
    "    # Ensure audio is within [-1, 1]\n",
    "    max_amplitude = max(abs(audio))\n",
    "    audio = audio / max_amplitude\n",
    "    return audio\n",
    "\n",
    "def create_mixture(percussion_audio, noise_audio, k):\n",
    "    percussion_audio = k * percussion_audio\n",
    "    noise_audio = (1 - k) * noise_audio\n",
    "    mixture_audio = percussion_audio + noise_audio\n",
    "    return mixture_audio\n",
    "\n",
    "# Dataset Creation\n",
    "def create_dataset(metadata_noise, output_dir, num_mixes=7358, target_loudness=-3, max_noise_classes=2, k_values=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    # Create directories if they do not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create a list for storing metadata\n",
    "    metadata = []\n",
    "\n",
    "    # Iterate through the percussion files\n",
    "    percussion_files = sorted(os.listdir(DATASET_PERCUSSION_PATH)) \n",
    "    # keep wav files only\n",
    "    percussion_files = [f for f in percussion_files if f.endswith('.wav')]\n",
    "    \n",
    "    # Progress bar\n",
    "    for perc_idx, perc_file in enumerate(tqdm(percussion_files, desc=\"Creating Mixtures\")):\n",
    "        percussion_path = os.path.join(DATASET_PERCUSSION_PATH, perc_file)\n",
    "        percussion_audio = pad_audio_center(percussion_path)\n",
    "        percussion_audio = normalize_loudness(percussion_audio, target_loudness)\n",
    "\n",
    "        # Randomly select 1 or 2 noise classes for each mix\n",
    "        for _ in range(num_mixes // len(percussion_files)):\n",
    "            num_noise_classes = random.randint(1, max_noise_classes)\n",
    "            noise_classes = random.sample(noise_class_list, k=num_noise_classes)\n",
    "            k = random.choice(k_values)\n",
    "            noise_audio_combined = numpy.zeros_like(percussion_audio)\n",
    "\n",
    "            noise_files = []\n",
    "            noise_classes_str = []\n",
    "\n",
    "            # Load and mix noise files\n",
    "            for noise_class in noise_classes:\n",
    "                noise_row = metadata_noise[metadata_noise['class'] == noise_class].sample(n=1).iloc[0]\n",
    "                noise_file = os.path.join(DATASET_NOISE_PATH, f\"fold{noise_row['fold']}\", noise_row['slice_file_name'])\n",
    "                noise_audio = pad_audio_center(noise_file)\n",
    "                noise_audio = normalize_loudness(noise_audio, target_loudness)\n",
    "\n",
    "                # Add noise to combined noise audio\n",
    "                noise_audio_combined += noise_audio\n",
    "\n",
    "                # Keep track of noise files and classes\n",
    "                noise_files.append(noise_row['slice_file_name'])\n",
    "                noise_classes_str.append(noise_class)\n",
    "\n",
    "            # Create the final mixture\n",
    "            noise_audio_combined = normalize_loudness(noise_audio_combined, target_loudness)\n",
    "            mixture_audio = create_mixture(percussion_audio, noise_audio_combined, k)\n",
    "\n",
    "            # Save mixture audio\n",
    "            mix_file_name = f\"mixture_{perc_idx}_noise_{'_'.join(noise_classes)}_k_{k:.2f}.wav\"\n",
    "            mix_file_path = os.path.join(output_dir, mix_file_name)\n",
    "            sf.write(mix_file_path, mixture_audio, sample_rate)\n",
    "\n",
    "            # Append metadata\n",
    "            metadata.append({\n",
    "                'percussion_file': perc_file,\n",
    "                'mix_file': mix_file_name,\n",
    "                'noise_files': ','.join(noise_files),\n",
    "                'noise_classes': ','.join(noise_classes_str),\n",
    "                'k': k\n",
    "            })\n",
    "\n",
    "    # Save metadata to CSV\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    metadata_df.to_csv(os.path.join(output_dir, \"metadata.csv\"), index=False)\n",
    "    print(f\"Dataset and metadata saved in '{output_dir}'\")\n",
    "\n",
    "# Load noise metadata\n",
    "metadata_noise_path = os.path.join(DATASET_NOISE_PATH, \"UrbanSound8k.csv\")\n",
    "metadata_noise = pd.read_csv(metadata_noise_path)\n",
    "\n",
    "# Change classID 8 to 6\n",
    "metadata_noise['classID'] = metadata_noise['classID'].replace(8, 6)\n",
    "# Sort by class ID and fold and reset index\n",
    "metadata_noise = metadata_noise.sort_values(\n",
    "    by=['classID', 'fold']).reset_index(drop=True)\n",
    "\n",
    "# # Get unique noise classes and their IDs\n",
    "# noise_class = metadata_noise['class'].unique()\n",
    "# noise_classID = metadata_noise['classID'].unique()\n",
    "\n",
    "# # Create a DataFrame for noise classes\n",
    "# noise_data = {\n",
    "#     'class': noise_class,\n",
    "#     'classID': noise_classID,\n",
    "#     'count': [len(metadata_noise[metadata_noise['class'] == c]) for c in noise_class],\n",
    "# }\n",
    "# df = pd.DataFrame(noise_data)\n",
    "\n",
    "# Create dataset with mixtures and save metadata\n",
    "output_dir = DATASET_MIX_AUDIO_PATH\n",
    "create_dataset(metadata_noise, output_dir, num_mixes=7358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a389b085-dc50-46da-a182-afcbe8d67683",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DATASET_PERCUSSION_PATH, DATASET_NOISE_PATH, DATASET_MIX_AUDIO_PATH\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# # Load metadata\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(metadata_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyloudnorm as pyln\n",
    "import random\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "from config import DATASET_PERCUSSION_PATH, DATASET_NOISE_PATH, DATASET_MIX_AUDIO_PATH\n",
    "\n",
    "# # Load metadata\n",
    "metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef8c21-e05d-4ad6-8399-e5bdec53e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['percussion_file', 'mix_file', 'noise_files', 'noise_classes', 'k'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723dc4b-4457-4f00-b5ec-1d6c0275cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique noise classes: 64\n",
      "The count of each k value: k\n",
      "0.9    1499\n",
      "0.5    1496\n",
      "0.6    1460\n",
      "0.8    1457\n",
      "0.7    1441\n",
      "Name: count, dtype: int64\n",
      "The number of unique percussion files: 387\n",
      "The number of unique mix files: 6879\n",
      "The number of unique noise files: 6546\n",
      "The count of each noise file: noise_files\n",
      "162541-1-1-0.wav                    6\n",
      "65472-1-0-0.wav                     5\n",
      "161010-1-2-0.wav                    5\n",
      "57584-4-0-5.wav                     4\n",
      "196070-2-0-1.wav                    4\n",
      "                                   ..\n",
      "155311-3-0-0.wav                    1\n",
      "94636-8-0-15.wav                    1\n",
      "159745-8-1-5.wav                    1\n",
      "22601-8-0-33.wav,99812-1-0-0.wav    1\n",
      "105029-7-2-7.wav                    1\n",
      "Name: count, Length: 6546, dtype: int64\n",
      "[2 1 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of unique noise classes: {metadata['noise_classes'].nunique()}\")\n",
    "print(f\"The count of each k value: {metadata['k'].value_counts()}\")\n",
    "print(f\"The number of unique percussion files: {metadata['percussion_file'].nunique()}\")\n",
    "print(f\"The number of unique mix files: {metadata['mix_file'].nunique()}\")\n",
    "print(f\"The number of unique noise files: {metadata['noise_files'].nunique()}\")\n",
    "print(f\"The count of each noise file: {metadata['noise_files'].value_counts()}\")\n",
    "print(metadata.groupby(\"noise_files\").size().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1942dd14-6531-42e0-add1-58e4c249dacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6546.000000\n",
      "mean        1.123281\n",
      "std         0.404239\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         6.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(metadata.groupby(\"noise_files\").size().describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
